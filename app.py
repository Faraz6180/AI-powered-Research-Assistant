import streamlit as st
import time
from langchain_groq import ChatGroq
from langchain_community.utilities import ArxivAPIWrapper, WikipediaAPIWrapper
from langchain_community.tools import ArxivQueryRun, WikipediaQueryRun, DuckDuckGoSearchRun
from langchain.agents import create_openai_tools_agent, AgentExecutor
from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder

# =========================
# PAGE CONFIG
# =========================
st.set_page_config(
    page_title="AI Research Copilot",
    page_icon="üöÄ",
    layout="wide"
)

# =========================
# PREMIUM CSS
# =========================
st.markdown("""
<style>
body {
    background: linear-gradient(135deg,#0f0c29,#302b63,#24243e);
}
.main-title {
    font-size: 3.2rem;
    font-weight: 800;
    text-align: center;
    background: linear-gradient(90deg,#667eea,#764ba2,#f093fb);
    -webkit-background-clip: text;
    -webkit-text-fill-color: transparent;
}
.subtitle {
    text-align: center;
    color: #cbd5e1;
    margin-bottom: 2rem;
}
.card {
    background: rgba(255,255,255,0.06);
    padding: 1.5rem;
    border-radius: 16px;
    margin-bottom: 1rem;
    color: #e2e8f0;
}
</style>
""", unsafe_allow_html=True)

# =========================
# HEADER
# =========================
st.markdown('<div class="main-title">üöÄ AI Research Copilot</div>', unsafe_allow_html=True)
st.markdown(
    '<div class="subtitle">Multi-Source AI Research Assistant | ArXiv + Wikipedia + Web Search</div>',
    unsafe_allow_html=True
)

# =========================
# SIDEBAR
# =========================
with st.sidebar:
    st.markdown("## ‚öôÔ∏è Configuration")

    demo_mode = st.toggle("üß™ Demo Mode (No API Key)", value=False)

    api_key = st.text_input(
        "Groq API Key",
        type="password",
        disabled=demo_mode,
        help="Get free key: https://console.groq.com/keys"
    )

    if not demo_mode and not api_key:
        st.warning("Enter API key or enable Demo Mode")
    elif api_key:
        st.success("API Key configured")

    model = st.selectbox(
        "Model",
        ["llama-3.3-70b-versatile", "llama-3.1-70b-versatile", "mixtral-8x7b-32768"],
        index=0
    )

    st.markdown("---")
    st.markdown("### üèÜ Winning Features")
    st.markdown("""
    - Multi-source verification
    - Real-time research synthesis
    - Groq-powered speed
    - Citation tracking
    """)
    
    st.markdown("---")
    st.markdown("### üí° Try These:")
    
    if st.button("üî¨ Quantum Computing", use_container_width=True):
        st.session_state.example = "What are the latest breakthroughs in quantum computing?"
    
    if st.button("ü§ñ Transformers in NLP", use_container_width=True):
        st.session_state.example = "How do transformer models work in natural language processing?"
    
    if st.button("üß¨ CRISPR Applications", use_container_width=True):
        st.session_state.example = "What are the latest applications of CRISPR technology?"
    
    if st.button("üìä Deep Learning", use_container_width=True):
        st.session_state.example = "Explain deep learning and its applications"

# =========================
# LAYOUT
# =========================
left, right = st.columns([7, 3])

with right:
    st.markdown('''
    <div class="card">
        <b>Perfect For</b><br>
        üéì Academic Research<br>
        üî¨ Scientific Papers<br>
        üë®‚Äçüíª Technical Learning
    </div>
    ''', unsafe_allow_html=True)
    
    st.markdown('''
    <div class="card">
        <b>What Makes This Win</b><br>
        ‚Ä¢ 3 sources in parallel<br>
        ‚Ä¢ AI synthesis<br>
        ‚Ä¢ Verified citations<br>
        ‚Ä¢ Lightning fast
    </div>
    ''', unsafe_allow_html=True)
    
    if "messages" in st.session_state and len(st.session_state.messages) > 1:
        msg_count = len([m for m in st.session_state.messages if m["role"] == "user"])
        st.markdown(f'<div class="card"><b>Research Queries</b><br>üìä {msg_count}</div>', unsafe_allow_html=True)

# =========================
# CHAT STATE
# =========================
if "messages" not in st.session_state:
    st.session_state.messages = [{
        "role": "assistant",
        "content": "üëã I'm your AI Research Copilot. Ask any research question and I'll search ArXiv papers, Wikipedia, and the web to give you a comprehensive, cited answer."
    }]

# Handle example queries
if "example" in st.session_state:
    user_query = st.session_state.example
    del st.session_state.example
    st.session_state.messages.append({"role": "user", "content": user_query})
    st.rerun()

# =========================
# DISPLAY CHAT
# =========================
with left:
    for msg in st.session_state.messages:
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])

    user_query = st.chat_input("Ask a research question...", disabled=(not demo_mode and not api_key))

# =========================
# HANDLE QUERY
# =========================
if user_query:
    st.session_state.messages.append({"role": "user", "content": user_query})

    with left:
        with st.chat_message("user"):
            st.markdown(user_query)

    # DEMO MODE
    if demo_mode:
        with left:
            with st.chat_message("assistant"):
                with st.spinner("Researching across multiple sources..."):
                    time.sleep(2)

                demo_answer = f"""
### üìö Research Summary

**Query:** {user_query}

Quantum computing leverages quantum mechanical phenomena to process information in fundamentally new ways. Recent developments include:

**Key Breakthroughs:**
- **Error Correction:** New topological codes reducing decoherence by 40%
- **Scalability:** IBM's 433-qubit Osprey processor (2024)
- **Algorithms:** Improved variational quantum eigensolvers for chemistry

**Applications:**
- Drug discovery and molecular simulation
- Cryptography and secure communications
- Financial modeling and optimization
- Machine learning acceleration

**Challenges:**
- Maintaining quantum coherence at scale
- Error rates in quantum gates
- Cost of cryogenic infrastructure

### üìñ Sources

- **[ArXiv]** Preskill, J. (2023). *Quantum Computing in the NISQ Era*
- **[Wikipedia]** Quantum Computing - Principles and Applications
- **[Web]** IBM Quantum Blog - Latest Updates (Dec 2024)

---
*Demo Mode: Toggle off and add API key for real-time research*
"""
                st.markdown(demo_answer)
                st.success("Research complete!")
                
                st.download_button(
                    "üì• Download Report",
                    demo_answer,
                    file_name="research_report.md",
                    mime="text/markdown"
                )

        st.session_state.messages.append({"role": "assistant", "content": demo_answer})

    # REAL MODE
    else:
        if not api_key:
            with left:
                with st.chat_message("assistant"):
                    st.error("‚ö†Ô∏è Please enter your Groq API key in the sidebar!")
        else:
            try:
                with left:
                    with st.chat_message("assistant"):
                        # Initialize tools
                        arxiv = ArxivQueryRun(
                            api_wrapper=ArxivAPIWrapper(
                                top_k_results=1,
                                doc_content_chars_max=1000
                            )
                        )
                        
                        wiki = WikipediaQueryRun(
                            api_wrapper=WikipediaAPIWrapper(
                                top_k_results=1,
                                doc_content_chars_max=1000
                            )
                        )
                        
                        search = DuckDuckGoSearchRun(name="Search")
                        
                        tools = [wiki, arxiv, search]
                        
                        # Initialize LLM
                        llm = ChatGroq(
                            groq_api_key=api_key,
                            model_name=model,
                            temperature=0.5,
                            max_tokens=2000
                        )
                        
                        # Create prompt
                        prompt = ChatPromptTemplate.from_messages([
                            ("system", """You are a research assistant that provides comprehensive answers with citations.

When answering:
1. Use all available tools to gather information
2. Synthesize findings from multiple sources
3. Always cite your sources clearly
4. Format response with clear sections

Be thorough but concise."""),
                            MessagesPlaceholder(variable_name="chat_history", optional=True),
                            ("human", "{input}"),
                            MessagesPlaceholder(variable_name="agent_scratchpad")
                        ])
                        
                        # Create agent
                        agent = create_openai_tools_agent(llm, tools, prompt)
                        agent_executor = AgentExecutor(
                            agent=agent,
                            tools=tools,
                            verbose=False,
                            handle_parsing_errors=True,
                            max_iterations=8
                        )
                        
                        # Execute
                        with st.spinner("üîç Searching ArXiv, Wikipedia, and Web..."):
                            result = agent_executor.invoke({"input": user_query})
                        
                        answer = result.get("output", "No response generated")
                        
                        # Format if needed
                        if "Sources" not in answer:
                            formatted_answer = f"""
### Answer

{answer}

### Sources
- ArXiv Research Papers
- Wikipedia Encyclopedia
- Web Search Results
"""
                            answer = formatted_answer
                        
                        st.markdown("---")
                        st.markdown(answer)
                        st.success("‚úÖ Research complete!")
                        
                        st.download_button(
                            "üì• Download Report",
                            answer,
                            file_name="research_report.md",
                            mime="text/markdown"
                        )

                st.session_state.messages.append({"role": "assistant", "content": answer})

            except Exception as e:
                error_msg = str(e)
                
                with left:
                    with st.chat_message("assistant"):
                        if "401" in error_msg or "Unauthorized" in error_msg:
                            st.error("‚ùå Invalid API Key")
                            st.info("Get a new key from: https://console.groq.com/keys")
                        elif "429" in error_msg or "rate limit" in error_msg.lower():
                            st.error("‚ùå Rate Limit Exceeded")
                            st.info("Wait 60 seconds and try again")
                        else:
                            st.error(f"‚ùå Error: {error_msg}")
                            st.info("Try Demo Mode to see how it works")

# Footer
st.markdown("---")
col1, col2, col3 = st.columns(3)
with col1:
    st.markdown("**üî¨ Sources**")
    st.markdown("ArXiv ‚Ä¢ Wikipedia ‚Ä¢ Web")
with col2:
    st.markdown("**‚ö° Powered By**")
    st.markdown("Groq AI ‚Ä¢ LangChain")
with col3:
    st.markdown("**üìä Features**")
    st.markdown("Multi-Source ‚Ä¢ Citations ‚Ä¢ Fast")
